#/usr/bin/env python

import requests
from bs4 import BeautifulSoup
import urllib.parse as urlparse

# import urlparse
# from BeautifulSoup import BeautifulSoup

def request(url):
    try:
        return requests.get(url)
    except requests.exceptions.ConnectionError:
        pass

def extract_form(url):
    response = request(url)
    parsed_html = BeautifulSoup(response.content)
    # links_list = parsed_html.findAll("a")
    forms_list = parsed_html.findAll("form")

    for form in forms_list:
        action = form.get("action")
        print("[+] Action discovered: " + action)
        post_url = urlparse.urljoin(target_url, action)

        method = form.get("method")
        print("[+] Method discovered: " + method)

        input_list = form.findAll("input")
        post_data = {}

        for input in input_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value")
            print("[+] Input name discovered: " + input_name)

            if input_type == "text":
                input_value = "test"

            post_data[input_name] = input_value
        result = requests.post(post_url, data=post_data)
        print(result.content)

def extract_label_from(url, label):
    response = request(url)
    parsed_html = BeautifulSoup(response.content)
    labels_list = parsed_html.findAll(str(label))
    return labels_list

def extract_attribute(labels_list, attr):
    for label in labels_list:
        attribute = label.get(str(attr))
        print(attribute)

target_url = "http://192.168.140.129/mutillidae/index.php?page=dns-lookup.php"
extract_form(target_url)
# form_list = extract_label_from(target_url, "form")
# extract_attribute(form_list, "action")
